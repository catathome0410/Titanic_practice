{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d80e54",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# 自动检测环境\n",
        "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
        "competition_name = 'titanic/'\n",
        "\n",
        "if IS_KAGGLE:\n",
        "    print(\"Running on Kaggle\")\n",
        "    DATA_PATH = '/kaggle/input/' + competition_name\n",
        "    OUTPUT_PATH = '/kaggle/working'\n",
        "    # 可能需要安装包\n",
        "else:\n",
        "    print(\"Running locally\")\n",
        "    DATA_PATH = './data'\n",
        "    OUTPUT_PATH = './output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "646703d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a0aa18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add src directory to Python path and import model\n",
        "if IS_KAGGLE:\n",
        "    !git clone https://github.com/catathome0410/Titanic_practice.git\n",
        "    import sys\n",
        "    sys.path.append('/kaggle/working/Titanic_practice/src')\n",
        "else:\n",
        "    sys.path.append('./src')\n",
        "\n",
        "from model import log_R_solver, NN_solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9980ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv(DATA_PATH + '/train.csv')\n",
        "test = pd.read_csv(DATA_PATH + '/test.csv')\n",
        "Y_train = np.array(train['Survived'])\n",
        "train = train.drop(['Survived'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c0ecec",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Preprocessor_forT:\n",
        "    def __init__(self):\n",
        "        self.processor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', StandardScaler(), ['Age']),\n",
        "                ('cat', OneHotEncoder(\n",
        "                    sparse_output=False, \n",
        "                    handle_unknown='ignore',\n",
        "                    dtype=np.int32), ['Pclass', 'Embarked', 'name_title', 'Cabin_class', 'Fare_class'])\n",
        "            ],\n",
        "            remainder='passthrough'\n",
        "        )\n",
        "\n",
        "    def has_alias(self, row):\n",
        "        str0 = row['Name']\n",
        "        return str0.find('(') >= 0 or str0.find('\"') >=0\n",
        "\n",
        "    def double_family_name(self, row):\n",
        "        str0 = row['Name']\n",
        "        loc0 = str0.find(', ')\n",
        "        loc1 = str0.find(' ')\n",
        "        return loc1 < loc0\n",
        "\n",
        "    def find_title(self, row):\n",
        "        str0 = row['Name']\n",
        "        loc0 = str0.find(', ')\n",
        "        loc1 = str0.find('. ')\n",
        "        return str0[loc0+2 : loc1]\n",
        "\n",
        "    ## Fare : < 10, <32, <90, <200\n",
        "    def fare_class(self, row):\n",
        "        if row['Fare'] < 10:\n",
        "            res = 'low'\n",
        "        elif row['Fare'] < 32:\n",
        "            res = 'midlow'\n",
        "        elif row['Fare'] < 90:\n",
        "            res = 'mid'\n",
        "        elif row['Fare'] < 200:\n",
        "            res = 'midhigh'\n",
        "        else:\n",
        "            res = 'high'\n",
        "        return res\n",
        "\n",
        "    def cabin_class(self, row):\n",
        "        if row['Cabin'].find(' ') >= 0:\n",
        "            res = 'S'\n",
        "        else:\n",
        "            res = row['Cabin'][0]\n",
        "        return res\n",
        "\n",
        "    def clean_transform(self, df):\n",
        "        df_train = df.copy()\n",
        "        df_train['Embarked'] = df_train['Embarked'].fillna('S')\n",
        "        df_train = df_train.drop(['Ticket'], axis = 1)\n",
        "        df_train['name_title'] = df_train.apply(self.find_title, axis = 1)\n",
        "        df_train['double_family_name'] = df_train.apply(self.double_family_name, axis = 1)\n",
        "        df_train['has_alias'] = df_train.apply(self.has_alias, axis = 1)\n",
        "        df_train['Age_present'] = df_train['Age'].isna() == False\n",
        "        df_train['Age'] = df_train['Age'].fillna(0)\n",
        "        df_train['name_title'] = df_train.apply(lambda row: row['name_title'] if row['name_title'] in ('Mr', 'Miss', 'Mrs', 'Master', 'Dr', 'Rev') else 'other', axis = 1)\n",
        "        df_train['Cabin_present'] = df_train['Cabin'].isna() == False\n",
        "        df_train['Fare_class'] = df_train.apply(self.fare_class, axis = 1)\n",
        "        df_train['Cabin'] = df_train['Cabin'].fillna('None')\n",
        "        df_train['Cabin_class'] = df_train.apply(self.cabin_class, axis = 1)\n",
        "        df_train['Sex_male'] = df_train['Sex'] == 'male'\n",
        "        df_train = df_train.drop(['Sex', 'Name', 'Cabin', 'PassengerId', 'Fare'], axis = 1)\n",
        "        df_train = df_train.astype({\n",
        "            'double_family_name': 'int32',\n",
        "            'has_alias': 'int32',\n",
        "            'Age_present': 'int32',\n",
        "            'Cabin_present': 'int32',\n",
        "            'Sex_male': 'int32',\n",
        "        })\n",
        "\n",
        "        return df_train\n",
        "        \n",
        "    def fit(self, df):\n",
        "        df_processed = self.clean_transform(df)\n",
        "        self.processor.fit(df_processed)\n",
        "\n",
        "        return True\n",
        "\n",
        "    def transform(self, df):\n",
        "        df_processed = self.clean_transform(df)\n",
        "        df_processed = self.processor.transform(df_processed)\n",
        "\n",
        "\n",
        "        return df_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f6641a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "prssr = Preprocessor_forT()\n",
        "prssr.fit(train)\n",
        "X_train = prssr.transform(train)\n",
        "X_test = prssr.transform(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5be9ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "n_pick_0 = np.floor(X_train.shape[0] / 16)\n",
        "print(n_pick_0)\n",
        "n_pick = 54 * 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd41343",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=9, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "513d53b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# n_pick_arr = []\n",
        "# avg_train_acc = []\n",
        "# avg_dev_acc = []\n",
        "# std_train_acc = []\n",
        "# std_dev_acc = []\n",
        "\n",
        "# for i in range(6):\n",
        "#     n_pick = (i+1) * 9 * 16\n",
        "#     # kf = KFold(n_splits=9, shuffle=True, random_state=42)\n",
        "#     Xs = X_train[:n_pick, :]\n",
        "#     Ys = Y_train[:n_pick]\n",
        "\n",
        "#     kf = KFold(n_splits=9, shuffle=True)\n",
        "#     model_accuracies_dev = []\n",
        "#     model_accuracies_train = []\n",
        "\n",
        "#     for train_idx, test_idx in kf.split(Xs):\n",
        "#         Xss_train, Xss_test = Xs[train_idx], Xs[test_idx]\n",
        "#         yss_train, yss_test = Ys[train_idx], Ys[test_idx]\n",
        "        \n",
        "#         model = log_R_solver(Xss_train, yss_train, alpha = 0.03, lambda2=0.01)\n",
        "#         model.fit_L2()\n",
        "\n",
        "#         y_train_pred = model.transfrom(Xss_train)\n",
        "#         accuracy = np.sum(yss_train == y_train_pred) / yss_train.shape[0]\n",
        "#         model_accuracies_train.append(accuracy)\n",
        "        \n",
        "#         y_test_pred = model.transfrom(Xss_test)\n",
        "#         accuracy = np.sum(yss_test == y_test_pred) / yss_test.shape[0]\n",
        "#         model_accuracies_dev.append(accuracy)\n",
        "\n",
        "#     print(f\"train 平均 accuracy: {np.mean(model_accuracies_train):.4f}\")\n",
        "#     print(f\"train accuracy 标准差: {np.std(model_accuracies_train):.4f}\")\n",
        "#     print(f\"dev 平均 accuracy: {np.mean(model_accuracies_dev):.4f}\")\n",
        "#     print(f\"dev accuracy 标准差: {np.std(model_accuracies_dev):.4f}\")\n",
        "\n",
        "#     n_pick_arr.append(n_pick)\n",
        "#     avg_train_acc.append(np.mean(model_accuracies_train))\n",
        "#     avg_dev_acc.append(np.mean(model_accuracies_dev))\n",
        "#     std_train_acc.append(np.std(model_accuracies_train))\n",
        "#     std_dev_acc.append(np.std(model_accuracies_dev))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2a001a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# # First subplot: y1 and y2\n",
        "# ax1.plot(n_pick_arr, avg_train_acc, 'r-', linewidth=2, label='avg train acc')\n",
        "# ax1.plot(n_pick_arr, avg_dev_acc, 'b--', linewidth=2, label='avg dev acc')\n",
        "# ax1.set_xlabel('X axis', fontsize=12)\n",
        "# ax1.set_ylabel('Y axis', fontsize=12)\n",
        "# ax1.set_title('Plot 1: avg accuracy', fontsize=14)\n",
        "# ax1.legend(fontsize=11)\n",
        "# ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# # Second subplot: y3 and y4\n",
        "# ax2.plot(n_pick_arr, std_train_acc, 'r-', linewidth=2, label='std train acc')\n",
        "# ax2.plot(n_pick_arr, std_dev_acc, 'b--', linewidth=2, label='std dev acc')\n",
        "# ax2.set_xlabel('X axis', fontsize=12)\n",
        "# ax2.set_ylabel('Y axis', fontsize=12)\n",
        "# ax2.set_title('Plot 2: std accuracy', fontsize=14)\n",
        "# ax2.legend(fontsize=11)\n",
        "# ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# fig.suptitle('alpha = 0.03, lambda2=0.01')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f0fde5",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ef3162",
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eddc149",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LgR_model = log_R_solver(X_train, Y_train, alpha = 0.02, lambda2=0.01)\n",
        "# LgR_model.fit_L2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99236b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_res_logr = LgR_model.transfrom(X_test)\n",
        "# df_test_for_o = test.copy()\n",
        "# df_test_for_o['Survived'] = y_res_logr\n",
        "# df_res = df_test_for_o[['PassengerId', 'Survived']]\n",
        "# df_res.to_csv(OUTPUT_PATH + 'v12_after_bv.csv', index=False, encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07f5f064",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcdc89e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "if IS_KAGGLE == False:\n",
        "    os.makedirs('output', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5871e7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_res = df_test[['PassengerId', 'Survived']]\n",
        "# df_res.to_csv(OUTPUT_PATH + '/v4_l2_reg.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773fc8ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "n_pick_0 = np.floor(X_train.shape[0] / 16)\n",
        "print(n_pick_0)\n",
        "n_pick = 54 * 16\n",
        "Xs = X_train[:n_pick, :]\n",
        "Ys = Y_train[:n_pick]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e82cde4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "n_pick_arr = []\n",
        "avg_train_acc = []\n",
        "avg_dev_acc = []\n",
        "std_train_acc = []\n",
        "std_dev_acc = []\n",
        "\n",
        "for i in range(6):\n",
        "    n_pick = (i+1) * 9 * 16\n",
        "    Xs = X_train[:n_pick, :]\n",
        "    Ys = Y_train[:n_pick]\n",
        "\n",
        "    # kf = KFold(n_splits=9, shuffle=True, random_state=42)\n",
        "    kf = KFold(n_splits=9, shuffle=True)\n",
        "    model_accuracies_dev = []\n",
        "    model_accuracies_train = []\n",
        "\n",
        "    for train_idx, test_idx in kf.split(Xs):\n",
        "        Xss_train, Xss_test = Xs[train_idx], Xs[test_idx]\n",
        "        yss_train, yss_test = Ys[train_idx], Ys[test_idx]\n",
        "        \n",
        "        model = NN_solver(Xss_train, yss_train, alpha=0.02, n_seed = 200, output_gap = 100)\n",
        "        model.fit_shallow_parallel(shallow_iter_limit = 2000, target_loss = 320)\n",
        "\n",
        "        n_min_seed = model.loss_arr.argmin()\n",
        "        model.fit_deep(10000, lr_raito = 0.1, use_input = True, W1_i=model.W1[:, :, n_min_seed], b1_i=model.b1[:, :, n_min_seed], W2_i=model.W2[:, :, n_min_seed], b2_i=model.b2[:, :, n_min_seed], W3_i=model.W3[:, :, n_min_seed], b3_i=model.b3[:, :, n_min_seed])\n",
        "        \n",
        "        accuracy = model.check_performance(Xss_test, yss_test)\n",
        "        model_accuracies_dev.append(accuracy)\n",
        "\n",
        "        accuracy = model.check_performance(Xss_train, yss_train)\n",
        "        model_accuracies_train.append(accuracy)\n",
        "\n",
        "    n_pick_arr.append(n_pick)\n",
        "    avg_train_acc.append(np.mean(model_accuracies_train))\n",
        "    avg_dev_acc.append(np.mean(model_accuracies_dev))\n",
        "    std_train_acc.append(np.std(model_accuracies_train))\n",
        "    std_dev_acc.append(np.std(model_accuracies_dev))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12affd0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    'n_data': n_pick_arr,\n",
        "    'avg_train_accuracy': avg_train_acc,\n",
        "    'avg_dev_accuracy': avg_dev_acc,\n",
        "    'std_train_accuracy': std_train_acc,\n",
        "    'std_dev_accuracy': std_dev_acc\n",
        "})\n",
        "\n",
        "df.to_csv(OUTPUT_PATH + 'nn_acc_curve_a001.csv', index=False, encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6413752f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2a8222",
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_res_logr = nslr.predict(X_test)\n",
        "# df_test_for_o = test.copy()\n",
        "# df_test_for_o['Survived'] = y_res_logr\n",
        "# df_res = df_test_for_o[['PassengerId', 'Survived']]\n",
        "# df_res.to_csv(OUTPUT_PATH + 'v14_nn_new_feature.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65f5fd86",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 就 NN的效果来说已经很好了，接下来要提升titanic 的数据效果是ML hyper parametr tuning 和feature engineering 方面的工作\n",
        "    \n",
        "    ## K-fold training, (check)\n",
        "    ## Roc curve, precision / recall \n",
        "## 把Titanic 剩下的几个feature 挖出点东西来. Name / Cabin / \n",
        "## Bias / Variance curve\n",
        "## NN variance tuning, 剪枝，regularization, early stopping 这些"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
