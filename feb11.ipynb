{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d80e54",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# 自动检测环境\n",
        "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
        "competition_name = 'competitions/titanic'\n",
        "\n",
        "if IS_KAGGLE:\n",
        "    print(\"Running on Kaggle\")\n",
        "    DATA_PATH = '/kaggle/input/' + competition_name\n",
        "    OUTPUT_PATH = '/kaggle/working'\n",
        "    # 可能需要安装包\n",
        "else:\n",
        "    print(\"Running locally\")\n",
        "    DATA_PATH = './data'\n",
        "    OUTPUT_PATH = './output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "646703d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler # 根据需要选用\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# KLIEP 重加权适配器（用于 pipeline）\n",
        "from skada import KLIEPReweightAdapter\n",
        "\n",
        "\n",
        "\n",
        "# 随机森林模型\n",
        "from sklearn.ensemble import RandomForestClassifier  # 分类问题\n",
        "# from sklearn.ensemble import RandomForestRegressor # 回归问题\n",
        "\n",
        "# 模型评估\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a440c23",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 用来画有中文注释的pyplot的\n",
        "import matplotlib\n",
        "\n",
        "\n",
        "# 在创建图形之前设置字体\n",
        "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
        "# macOS系统可用的中文字体（按优先级排序）\n",
        "matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC', 'STHeiti', 'Microsoft YaHei', 'WenQuanYi Micro Hei']\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
        "\n",
        "# 可选：查看哪些字体被实际使用\n",
        "print(\"当前使用的字体列表:\", matplotlib.rcParams['font.sans-serif'])\n",
        "print(\"当前字体家族:\", matplotlib.rcParams['font.family'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a0aa18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add src directory to Python path and import model\n",
        "if IS_KAGGLE:\n",
        "    !git clone https://github.com/catathome0410/Titanic_practice.git\n",
        "    import sys\n",
        "    sys.path.append('/kaggle/working/Titanic_practice/src')\n",
        "else:\n",
        "    sys.path.append('./src')\n",
        "\n",
        "from model import log_R_solver, NN_solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9980ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv(DATA_PATH + '/train.csv')\n",
        "test = pd.read_csv(DATA_PATH + '/test.csv')\n",
        "train['dataset'] = 'train'\n",
        "test['dataset'] = 'test'\n",
        "Y_train = np.array(train['Survived'])\n",
        "train = train.drop(['Survived'], axis = 1)\n",
        "train_test = pd.concat([train, test])\n",
        "## 经验证，对模型没什么帮助，倒是covariant shift 挺大，所以直接不要了\n",
        "train_test = train_test.drop(['Embarked'], axis = 1)\n",
        "## ticket 几乎是乱码，没法用\n",
        "train_test = train_test.drop(['Ticket'], axis = 1)\n",
        "## drop 了呗，没什么用了\n",
        "train_test = train_test.drop(['PassengerId'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7540eb43",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 统计缺失值比例\n",
        "train_test.isna().sum(axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "046a90b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_test['Fare'] = train_test['Fare'].fillna(train_test['Fare'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845cb1ee",
      "metadata": {},
      "source": [
        "下面处理Age的缺失值，先做出name_title列，然后用相应name_title, pclass值的组的中位数填充缺失"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d5f0bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_title(row):\n",
        "    str0 = row['Name']\n",
        "    loc0 = str0.find(', ')\n",
        "    loc1 = str0.find('. ')\n",
        "    return str0[loc0+2 : loc1]\n",
        "\n",
        "train_test['Age_missing'] = train_test['Age'].isna()\n",
        "train_test['name_title'] = train_test.apply(find_title, axis = 1)\n",
        "train_test['name_title'] = train_test['name_title'].replace('Ms', 'Miss')\n",
        "train_test['name_title'] = train_test['name_title'].replace('Mlle', 'Miss')\n",
        "train_test['name_title'] = train_test['name_title'].replace('Mme', 'Mrs')\n",
        "train_test['name_title'] = np.where(~train_test['name_title'].isin(['Mr', 'Miss', 'Mrs', 'Master']), 'Rare', train_test['name_title'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22c1277",
      "metadata": {},
      "outputs": [],
      "source": [
        "import duckdb\n",
        "result = duckdb.query(\"\"\"\n",
        "    SELECT \n",
        "    Pclass, name_title, count(*) n_count, round(avg(Age),2) avg_age, median(Age) med_age, sum(Age_missing) Age_miss\n",
        "    FROM train_test \n",
        "    group by 1,2\n",
        "    order by 3 desc\n",
        "    \n",
        "\"\"\").df()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b49d7dd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_test['Age'] = np.where(train_test['Age'].isna(), train_test.groupby(['name_title', 'Pclass'])['Age'].transform('median'), train_test['Age'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca74a56",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "def has_alias(row):\n",
        "    str0 = row['Name']\n",
        "    return str0.find('(') >= 0 or str0.find('\"') >=0\n",
        "\n",
        "def double_family_name(row):\n",
        "    str0 = row['Name']\n",
        "    loc0 = str0.find(', ')\n",
        "    loc1 = str0.find(' ')\n",
        "    return loc1 < loc0\n",
        "\n",
        "def cabin_class(row):\n",
        "    if row['Cabin'].find(' ') >= 0:\n",
        "        res = 'S'\n",
        "    else:\n",
        "        res = row['Cabin'][0]\n",
        "    return res\n",
        "\n",
        "\n",
        "train_test['double_family_name'] = train_test.apply(double_family_name, axis = 1)\n",
        "train_test['has_alias'] = train_test.apply(has_alias, axis = 1)\n",
        "train_test['FamilySize'] = train_test['SibSp'] + train_test['Parch'] + 1\n",
        "\n",
        "## Age 和Fare 的pct 值要按train set算，用train_test结合集算会造成数据泄漏\n",
        "def create_percentile_transformer(train_series):\n",
        "    \"\"\"\n",
        "    返回一个函数，可以将新数据映射到训练集的百分位\n",
        "    \"\"\"\n",
        "    def transform(x):\n",
        "        if pd.isna(x):\n",
        "            return np.nan\n",
        "        # 计算在训练集中的百分位\n",
        "        return stats.percentileofscore(train_series.dropna(), x) / 100\n",
        "    \n",
        "    return transform\n",
        "\n",
        "# 创建转换器\n",
        "age_transformer = create_percentile_transformer(train_test.loc[train_test['dataset'] == 'train','Age'])\n",
        "\n",
        "# 应用到两个数据集\n",
        "train_test.loc[train_test['dataset'] == 'train','Age_rank_pct'] = train_test.loc[train_test['dataset'] == 'train','Age'].apply(age_transformer)\n",
        "train_test.loc[train_test['dataset'] == 'test', 'Age_rank_pct'] = train_test.loc[train_test['dataset'] == 'test', 'Age'].apply(age_transformer)\n",
        "\n",
        "fare_transformer = create_percentile_transformer(train_test.loc[train_test['dataset'] == 'train','Fare'])\n",
        "\n",
        "train_test.loc[train_test['dataset'] == 'train','Fare_rank_pct'] = train_test.loc[train_test['dataset'] == 'train','Fare'].apply(fare_transformer)\n",
        "train_test.loc[train_test['dataset'] == 'test','Fare_rank_pct'] = train_test.loc[train_test['dataset'] == 'test','Fare'].apply(fare_transformer)\n",
        "\n",
        "\n",
        "train_test['Cabin_present'] = train_test['Cabin'].isna() == False\n",
        "\n",
        "train_test['Cabin'] = train_test['Cabin'].fillna('None')\n",
        "train_test['Cabin_class'] = train_test.apply(cabin_class, axis = 1)\n",
        "train_test['Sex_male'] = train_test['Sex'] == 'male'\n",
        "train_test = train_test.drop(['Sex', 'Name', 'Cabin', 'Age', 'Fare'], axis = 1)\n",
        "train_test = train_test.astype({\n",
        "    'double_family_name': 'int32',\n",
        "    'has_alias': 'int32',\n",
        "    'Age_missing': 'int32',\n",
        "    'Cabin_present': 'int32',\n",
        "    'Sex_male': 'int32',\n",
        "})\n",
        "\n",
        "train_test.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84c7a51b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 分析数值型特征的分布差异\n",
        "numerical_features = ['SibSp', 'Parch', 'Age_rank_pct', 'Fare_rank_pct']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "for idx, feature in enumerate(numerical_features):\n",
        "    row, col = idx // 2, idx % 2\n",
        "    \n",
        "    # 绘制KDE分布\n",
        "    for dataset in ['train', 'test']:\n",
        "        data = train_test[train_test['dataset'] == dataset][feature].dropna()\n",
        "        sns.kdeplot(data=data, label=dataset, ax=axes[row, col])\n",
        "    \n",
        "    # KS检验\n",
        "    train_data = train_test[train_test['dataset'] == 'train'][feature].dropna()\n",
        "    test_data = train_test[train_test['dataset'] == 'test'][feature].dropna()\n",
        "    ks_stat, p_value = stats.ks_2samp(train_data, test_data)\n",
        "    \n",
        "    axes[row, col].set_title(f'{feature}\\nKS检验 p值: {p_value:.4f}')\n",
        "    axes[row, col].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2467e76",
      "metadata": {},
      "source": [
        "下面做对抗检验部分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339d2a3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_test = train_test.drop(['dataset'], axis = 1)\n",
        "oneHotTsfm = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), ['name_title', 'Cabin_class'])\n",
        "    ],\n",
        "    remainder='passthrough',  # 其他列保留不变\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "oneHotTsfm.set_output(transform='pandas')\n",
        "dfX_train_test = oneHotTsfm.fit_transform(df_train_test)\n",
        "dfY_train_test = train_test.apply(lambda row: 1 if row['dataset'] == 'test' else 0, axis = 1)\n",
        "dfX_train_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dcf7035",
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,      # 森林中树木的数量，默认100\n",
        "    max_depth=None,        # 树的最大深度，None表示不限制，直到叶子节点纯净\n",
        "    min_samples_split=2,   # 内部节点再划分所需最小样本数\n",
        "    min_samples_leaf=1,    # 叶子节点最少样本数\n",
        "    random_state=42,       # 固定随机种子，保证结果可复现\n",
        "    n_jobs=-1              # 使用所有可用的CPU核心，加速训练\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c6510a",
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_model.fit(dfX_train_test, dfY_train_test)\n",
        "\n",
        "# 查看模型在训练集上的准确率（不要太在意，可能有轻微过拟合）\n",
        "train_accuracy = rf_model.score(dfX_train_test, dfY_train_test)\n",
        "print(f\"训练集准确率: {train_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4002ac88",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 假设你已经训练好了模型\n",
        "# rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 1. 获取预测概率（正类的概率）\n",
        "y_pred_proba = rf_model.predict_proba(dfX_train_test)[:, 1]  # [:, 1] 取正类的概率\n",
        "\n",
        "# 2. 计算AUC分数\n",
        "auc_score = roc_auc_score(dfY_train_test, y_pred_proba)\n",
        "print(f\"AUC分数: {auc_score:.4f}\")\n",
        "\n",
        "# 3. （可选）绘制ROC曲线\n",
        "fpr, tpr, thresholds = roc_curve(dfY_train_test, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, 'b-', label=f'ROC曲线 (AUC = {auc_score:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'r--', label='随机猜测')\n",
        "plt.xlabel('假正率 (False Positive Rate)')\n",
        "plt.ylabel('真正率 (True Positive Rate)')\n",
        "plt.title('ROC曲线')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# 创建DataFrame便于查看\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'feature': dfX_train_test.columns,\n",
        "    'importance': importances\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"特征重要性排序:\")\n",
        "print(feature_importance_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca04543",
      "metadata": {},
      "outputs": [],
      "source": [
        "dfX_train_test_A = prssr1.clean_transform(train_test)\n",
        "dfX_train_test_A['From_Test'] = Y_train_test\n",
        "dfX_train_test_A['From_Test'] = dfX_train_test_A.apply(lambda row: 'True' if row['From_Test'] == 1 else 'False', axis = 1)\n",
        "dfX_train_test_A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f972d0e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "df_chisq_test = pd.DataFrame(columns=['column_name', 'p_value'])\n",
        "# col_names = ['Pclass', 'Embarked', 'name_title', 'double_family_name', 'has_alias', 'Age_present', 'Cabin_present', 'Age_class', 'Fare_class', 'Cabin_class', 'Sex_male']\n",
        "col_names = ['Pclass', 'name_title', 'double_family_name', 'has_alias', 'Age_present', 'Cabin_present', 'Age_class', 'Fare_class', 'Cabin_class', 'Sex_male']\n",
        "\n",
        "\n",
        "for i, col_name in enumerate(col_names):\n",
        "    # 方法1：用pandas的crosstab创建列联表\n",
        "    contingency_table = pd.crosstab(dfX_train_test_A[col_name], dfX_train_test_A['From_Test'])\n",
        "\n",
        "    # 进行卡方检验\n",
        "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "    df_chisq_test.loc[i] = [col_name, p_value]\n",
        "\n",
        "    print(f\"\\n卡方检验结果: {col_name}\")\n",
        "    print(f\"p值: {p_value:.4f}\")\n",
        "    print()\n",
        "\n",
        "print(df_chisq_test.sort_values('p_value'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa88d7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_chisq_test.sort_values('p_value'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9436b3",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4c0582",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3cdfe2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f6641a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "prssr = Preprocessor_forT()\n",
        "prssr.fit(train)\n",
        "X_train = prssr.transform(train)\n",
        "X_test = prssr.transform(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5be9ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "n_pick_0 = np.floor(X_train.shape[0] / 16)\n",
        "print(n_pick_0)\n",
        "n_pick = 54 * 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd41343",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=9, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "513d53b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# n_pick_arr = []\n",
        "# avg_train_acc = []\n",
        "# avg_dev_acc = []\n",
        "# std_train_acc = []\n",
        "# std_dev_acc = []\n",
        "\n",
        "# for i in range(6):\n",
        "#     n_pick = (i+1) * 9 * 16\n",
        "#     # kf = KFold(n_splits=9, shuffle=True, random_state=42)\n",
        "#     Xs = X_train[:n_pick, :]\n",
        "#     Ys = Y_train[:n_pick]\n",
        "\n",
        "#     kf = KFold(n_splits=9, shuffle=True)\n",
        "#     model_accuracies_dev = []\n",
        "#     model_accuracies_train = []\n",
        "\n",
        "#     for train_idx, test_idx in kf.split(Xs):\n",
        "#         Xss_train, Xss_test = Xs[train_idx], Xs[test_idx]\n",
        "#         yss_train, yss_test = Ys[train_idx], Ys[test_idx]\n",
        "        \n",
        "#         model = log_R_solver(Xss_train, yss_train, alpha = 0.03, lambda2=0.01)\n",
        "#         model.fit_L2()\n",
        "\n",
        "#         y_train_pred = model.transfrom(Xss_train)\n",
        "#         accuracy = np.sum(yss_train == y_train_pred) / yss_train.shape[0]\n",
        "#         model_accuracies_train.append(accuracy)\n",
        "        \n",
        "#         y_test_pred = model.transfrom(Xss_test)\n",
        "#         accuracy = np.sum(yss_test == y_test_pred) / yss_test.shape[0]\n",
        "#         model_accuracies_dev.append(accuracy)\n",
        "\n",
        "#     print(f\"train 平均 accuracy: {np.mean(model_accuracies_train):.4f}\")\n",
        "#     print(f\"train accuracy 标准差: {np.std(model_accuracies_train):.4f}\")\n",
        "#     print(f\"dev 平均 accuracy: {np.mean(model_accuracies_dev):.4f}\")\n",
        "#     print(f\"dev accuracy 标准差: {np.std(model_accuracies_dev):.4f}\")\n",
        "\n",
        "#     n_pick_arr.append(n_pick)\n",
        "#     avg_train_acc.append(np.mean(model_accuracies_train))\n",
        "#     avg_dev_acc.append(np.mean(model_accuracies_dev))\n",
        "#     std_train_acc.append(np.std(model_accuracies_train))\n",
        "#     std_dev_acc.append(np.std(model_accuracies_dev))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2a001a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# # First subplot: y1 and y2\n",
        "# ax1.plot(n_pick_arr, avg_train_acc, 'r-', linewidth=2, label='avg train acc')\n",
        "# ax1.plot(n_pick_arr, avg_dev_acc, 'b--', linewidth=2, label='avg dev acc')\n",
        "# ax1.set_xlabel('X axis', fontsize=12)\n",
        "# ax1.set_ylabel('Y axis', fontsize=12)\n",
        "# ax1.set_title('Plot 1: avg accuracy', fontsize=14)\n",
        "# ax1.legend(fontsize=11)\n",
        "# ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# # Second subplot: y3 and y4\n",
        "# ax2.plot(n_pick_arr, std_train_acc, 'r-', linewidth=2, label='std train acc')\n",
        "# ax2.plot(n_pick_arr, std_dev_acc, 'b--', linewidth=2, label='std dev acc')\n",
        "# ax2.set_xlabel('X axis', fontsize=12)\n",
        "# ax2.set_ylabel('Y axis', fontsize=12)\n",
        "# ax2.set_title('Plot 2: std accuracy', fontsize=14)\n",
        "# ax2.legend(fontsize=11)\n",
        "# ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# fig.suptitle('alpha = 0.03, lambda2=0.01')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f0fde5",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ef3162",
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eddc149",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LgR_model = log_R_solver(X_train, Y_train, alpha = 0.02, lambda2=0.01)\n",
        "# LgR_model.fit_L2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99236b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_res_logr = LgR_model.transfrom(X_test)\n",
        "# df_test_for_o = test.copy()\n",
        "# df_test_for_o['Survived'] = y_res_logr\n",
        "# df_res = df_test_for_o[['PassengerId', 'Survived']]\n",
        "# df_res.to_csv(OUTPUT_PATH + 'v12_after_bv.csv', index=False, encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07f5f064",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcdc89e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "if IS_KAGGLE == False:\n",
        "    os.makedirs('output', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5871e7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_res = df_test[['PassengerId', 'Survived']]\n",
        "# df_res.to_csv(OUTPUT_PATH + '/v4_l2_reg.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773fc8ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# n_pick_0 = np.floor(X_train.shape[0] / 16)\n",
        "# print(n_pick_0)\n",
        "# n_pick = 54 * 16\n",
        "# Xs = X_train[:n_pick, :]\n",
        "# Ys = Y_train[:n_pick]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e82cde4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "n_pick_arr = []\n",
        "avg_train_acc = []\n",
        "avg_dev_acc = []\n",
        "std_train_acc = []\n",
        "std_dev_acc = []\n",
        "\n",
        "for i in range(6):\n",
        "    n_pick = (i+1) * 9 * 16\n",
        "    Xs = X_train[:n_pick, :]\n",
        "    Ys = Y_train[:n_pick]\n",
        "\n",
        "    # kf = KFold(n_splits=9, shuffle=True, random_state=42)\n",
        "    kf = KFold(n_splits=9, shuffle=True)\n",
        "    model_accuracies_dev = []\n",
        "    model_accuracies_train = []\n",
        "\n",
        "    for train_idx, test_idx in kf.split(Xs):\n",
        "        Xss_train, Xss_test = Xs[train_idx], Xs[test_idx]\n",
        "        yss_train, yss_test = Ys[train_idx], Ys[test_idx]\n",
        "        \n",
        "        model = NN_solver(Xss_train, yss_train, alpha=0.02, lambda2 = 0.03, n_seed = 200, output_gap = 100)\n",
        "        model.fit_shallow_parallel(shallow_iter_limit = 2000, target_loss = 320)\n",
        "\n",
        "        n_min_seed = model.loss_arr.argmin()\n",
        "        model.fit_deep(10000, lr_raito = 0.1, use_input = True, W1_i=model.W1[:, :, n_min_seed], b1_i=model.b1[:, :, n_min_seed], W2_i=model.W2[:, :, n_min_seed], b2_i=model.b2[:, :, n_min_seed], W3_i=model.W3[:, :, n_min_seed], b3_i=model.b3[:, :, n_min_seed])\n",
        "        \n",
        "        accuracy = model.check_performance(Xss_test, yss_test)\n",
        "        model_accuracies_dev.append(accuracy)\n",
        "\n",
        "        accuracy = model.check_performance(Xss_train, yss_train)\n",
        "        model_accuracies_train.append(accuracy)\n",
        "\n",
        "    n_pick_arr.append(n_pick)\n",
        "    avg_train_acc.append(np.mean(model_accuracies_train))\n",
        "    avg_dev_acc.append(np.mean(model_accuracies_dev))\n",
        "    std_train_acc.append(np.std(model_accuracies_train))\n",
        "    std_dev_acc.append(np.std(model_accuracies_dev))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12affd0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    'n_data': n_pick_arr,\n",
        "    'avg_train_accuracy': avg_train_acc,\n",
        "    'avg_dev_accuracy': avg_dev_acc,\n",
        "    'std_train_accuracy': std_train_acc,\n",
        "    'std_dev_accuracy': std_dev_acc\n",
        "})\n",
        "\n",
        "df.to_csv('nn_acc_curve_a002_l003.csv', index=False, encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2a8222",
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_res_logr = nslr.predict(X_test)\n",
        "# df_test_for_o = test.copy()\n",
        "# df_test_for_o['Survived'] = y_res_logr\n",
        "# df_res = df_test_for_o[['PassengerId', 'Survived']]\n",
        "# df_res.to_csv(OUTPUT_PATH + 'v14_nn_new_feature.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65f5fd86",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 就 NN的效果来说已经很好了，接下来要提升titanic 的数据效果是ML hyper parametr tuning 和feature engineering 方面的工作\n",
        "    \n",
        "    ## K-fold training, (check)\n",
        "    ## Roc curve, precision / recall \n",
        "## 把Titanic 剩下的几个feature 挖出点东西来. Name / Cabin / \n",
        "## Bias / Variance curve\n",
        "## NN variance tuning, 剪枝，regularization, early stopping 这些"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29489885",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "87c8e630",
      "metadata": {},
      "source": [
        "for plotting b/v curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2364ed6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_bv_curve = pd.read_csv(OUTPUT_PATH + '/nn_acc_curve_a003.csv')\n",
        "# df_bv_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e12d997e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# # First subplot: y1 and y2\n",
        "# ax1.plot(df_bv_curve[['n_data']], df_bv_curve[['avg_train_accuracy']], 'r-', linewidth=2, label='avg train acc')\n",
        "# ax1.plot(df_bv_curve[['n_data']], df_bv_curve[['avg_dev_accuracy']], 'b--', linewidth=2, label='avg dev acc')\n",
        "# ax1.set_xlabel('X axis', fontsize=12)\n",
        "# ax1.set_ylabel('Y axis', fontsize=12)\n",
        "# ax1.set_title('Plot 1: avg accuracy', fontsize=14)\n",
        "# ax1.legend(fontsize=11)\n",
        "# ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# # Second subplot: y3 and y4\n",
        "# ax2.plot(df_bv_curve[['n_data']], df_bv_curve[['std_train_accuracy']], 'r-', linewidth=2, label='std train acc')\n",
        "# ax2.plot(df_bv_curve[['n_data']], df_bv_curve[['std_dev_accuracy']], 'b--', linewidth=2, label='std dev acc')\n",
        "# ax2.set_xlabel('X axis', fontsize=12)\n",
        "# ax2.set_ylabel('Y axis', fontsize=12)\n",
        "# ax2.set_title('Plot 2: std accuracy', fontsize=14)\n",
        "# ax2.legend(fontsize=11)\n",
        "# ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# fig.suptitle('alpha = 0.03')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "655f335b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
